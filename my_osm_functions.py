# -*- coding: utf-8 -*-
"""my_osm_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MDlp1-ytHt-ClfscvxlhRxt9MFj-VARr
"""

# ============================================================
# my_osm_functions.py
# ============================================================

# ============================================================
# ðŸ”§ Import Library
# ============================================================
import os
import time
import hashlib
import osmnx as ox
import geopandas as gpd
import pandas as pd
import numpy as np
import folium
import networkx as nx
from shapely.geometry import Point
from shapely.ops import unary_union
from tqdm.notebook import tqdm
from folium.plugins import MarkerCluster
from matplotlib import cm, colors

# ============================================================
# ðŸ—‚ï¸ Setup Cache Folder untuk polygon OSM
# ============================================================
CACHE_DIR = "./osm_area_cache"
os.makedirs(CACHE_DIR, exist_ok=True)

def _slugify_name(name: str) -> str:
    s = str(name).strip().lower().replace(" ", "_")
    return "".join(ch for ch in s if ch.isalnum() or ch == "_")[:200]

def _cache_path_for_name(name: str) -> str:
    slug = _slugify_name(name)
    h = hashlib.sha1(name.encode("utf-8")).hexdigest()[:8]
    return os.path.join(CACHE_DIR, f"{slug}_{h}.geojson")

def _save_polygon_to_cache(geom, path):
    try:
        gpd.GeoDataFrame([{"geometry": geom}], crs="EPSG:4326").to_file(path, driver="GeoJSON")
    except Exception:
        pass

def _load_polygon_from_cache(path):
    try:
        gdf = gpd.read_file(path)
        return unary_union(gdf.geometry.values)
    except Exception:
        return None

# ============================================================
# ðŸ§© Helper: ambil nama administratif dari hasil geocode
# ============================================================
def _extract_admin_names_from_nominatim_raw(raw_addr: dict):
    kel_keys = ['suburb','village','hamlet','neighbourhood','locality','borough']
    kec_keys = ['county','district','city_district','municipality','suburb']
    kota_keys = ['city','town','municipality','village']
    prov_keys = ['state','region','province']

    def first(keys):
        for k in keys:
            v = raw_addr.get(k)
            if v:
                return v
        return None

    kel = first(kel_keys)
    kec = first(kec_keys)
    kota = first(kota_keys)
    prov = first(prov_keys)
    return kel, kec, kota, prov

# ============================================================
# ðŸ§­ Deteksi wilayah administratif & ambil polygon OSM (cached)
# ============================================================
def detect_and_fetch_admin_polygons(df, col_lat, col_lon, limit_per_level=200, sleep_between_requests=0.6):
    detected = []
    for _, row in tqdm(df.iterrows(), total=len(df), desc="reverse-geocode"):
        lat = row[col_lat]
        lon = row[col_lon]
        try:
            loc = ox.geocode_reverse((lat, lon), exactly_one=True)
            raw = loc.raw.get("address", {}) if hasattr(loc, "raw") else {}
            kel, kec, kota, prov = _extract_admin_names_from_nominatim_raw(raw)
            detected.append({'lat': lat, 'lon': lon, 'kelurahan': kel, 'kecamatan': kec, 'kota': kota, 'provinsi': prov})
        except Exception:
            detected.append({'lat': lat, 'lon': lon, 'kelurahan': None, 'kecamatan': None, 'kota': None, 'provinsi': None})
        time.sleep(sleep_between_requests)

    df_detect = pd.DataFrame(detected)

    # Pilih level terkecil yang tersedia kumulatif
    sel_level = None
    candidate_names = []
    kel_unique = [k for k in df_detect['kelurahan'].dropna().unique().tolist() if str(k).strip()!='']
    if len(kel_unique) > 0:
        sel_level = 'kelurahan'
        candidate_names = kel_unique
    else:
        kec_unique = [k for k in df_detect['kecamatan'].dropna().unique().tolist() if str(k).strip()!='']
        if len(kec_unique) > 0:
            sel_level = 'kecamatan'
            candidate_names = kec_unique
        else:
            kota_unique = [k for k in df_detect['kota'].dropna().unique().tolist() if str(k).strip()!='']
            if len(kota_unique) > 0:
                sel_level = 'kota'
                candidate_names = kota_unique
            else:
                prov_unique = [k for k in df_detect['provinsi'].dropna().unique().tolist() if str(k).strip()!='']
                if len(prov_unique) > 0:
                    sel_level = 'provinsi'
                    candidate_names = prov_unique

    if sel_level is None:
        buffers = [Point(r[col_lon], r[col_lat]).buffer(0.01) for _, r in df.iterrows()]
        area_union = unary_union(buffers)
        return area_union, df_detect

    candidate_names = candidate_names[:limit_per_level]

    # Ambil polygon tiap wilayah (cache first)
    polygons = []
    for name in tqdm(candidate_names, desc="ambil-poligon"):
        if not name or str(name).strip()=='': continue
        cache_path = _cache_path_for_name(f"{sel_level}:{name}")
        geom = None
        if os.path.exists(cache_path):
            geom = _load_polygon_from_cache(cache_path)
            if geom is not None:
                polygons.append(geom)
                continue
        try:
            query = f"{name}, Indonesia"
            gdf = ox.geocode_to_gdf(query)
            if gdf is not None and len(gdf) > 0:
                geom = gdf.geometry.iloc[0]
                polygons.append(geom)
                try:
                    _save_polygon_to_cache(geom, cache_path)
                except Exception:
                    pass
        except Exception:
            pass
        time.sleep(sleep_between_requests)

    if len(polygons) == 0:
        buffers = [Point(r[col_lon], r[col_lat]).buffer(0.01) for _, r in df.iterrows()]
        area_union = unary_union(buffers)
        return area_union, df_detect

    area_union = unary_union(polygons)
    return area_union, df_detect

# ============================================================
# ðŸ›£ï¸ Klasifikasi jalan
# ============================================================
def klasifikasi_jalan(hwy):
    if isinstance(hwy, list):
        hwy = hwy[0]
    if hwy in ['motorway','trunk','primary']:
        return 'utama'
    elif hwy in ['secondary','tertiary']:
        return 'sekunder'
    else:
        return 'lainnya'

# ============================================================
# ðŸš€ Fungsi utama: visualisasi peta adaptif network
# ============================================================
def visualisasi_peta_adaptif_network(df, summary_koordinat_v5_7,
                                     cutoff_levels=[1000,2000,5000],
                                     limit_area_names=200,
                                     sleep_between_requests=0.6):

    if summary_koordinat_v5_7 is None or 'Kolom' not in summary_koordinat_v5_7.columns:
        raise ValueError("summary_koordinat_v5_7 tidak valid")

    lat_candidates = summary_koordinat_v5_7.loc[
        summary_koordinat_v5_7['In_Range'].astype(str).str.contains('Latitude', case=False, na=False),
        'Kolom'
    ].tolist()
    lon_candidates = summary_koordinat_v5_7.loc[
        summary_koordinat_v5_7['In_Range'].astype(str).str.contains('Longitude', case=False, na=False),
        'Kolom'
    ].tolist()

    if len(lat_candidates) == 0 or len(lon_candidates) == 0:
        raise ValueError("summary_koordinat_v5_7 tidak mengandung In_Range 'Latitude'/'Longitude'.")

    col_lat = lat_candidates[0]
    col_lon = lon_candidates[0]

    df_work = df.copy()
    df_work[col_lat] = pd.to_numeric(df_work[col_lat], errors='coerce')
    df_work[col_lon] = pd.to_numeric(df_work[col_lon], errors='coerce')
    df_work = df_work.dropna(subset=[col_lat, col_lon]).reset_index(drop=True)

    area_union, df_detect = detect_and_fetch_admin_polygons(df_work, col_lat, col_lon,
                                                           limit_per_level=limit_area_names,
                                                           sleep_between_requests=sleep_between_requests)

    G = ox.graph_from_polygon(area_union, network_type='drive')
    edges = ox.graph_to_gdfs(G, nodes=False, edges=True)
    edges['kategori'] = edges['highway'].apply(klasifikasi_jalan)

    jalan_utama_nodes = {u for u, v, k in G.edges(keys=True) if G[u][v][k].get('highway') in ['primary','trunk']}
    jalan_sekunder_nodes = {u for u, v, k in G.edges(keys=True) if G[u][v][k].get('highway') in ['secondary','tertiary']}

    gdf_titik = gpd.GeoDataFrame(df_work.copy(),
                                geometry=gpd.points_from_xy(df_work[col_lon], df_work[col_lat]),
                                crs='EPSG:4326')

    def jarak_ke_jalan(G, point, target_nodes, cutoff_list):
        try:
            nearest_node = ox.distance.nearest_nodes(G, point.x, point.y)
        except Exception:
            return np.nan
        for cutoff in cutoff_list:
            try:
                dist = nx.single_source_dijkstra_path_length(G, nearest_node, weight='length', cutoff=cutoff)
                jarak = [v for k, v in dist.items() if k in target_nodes]
                if len(jarak) > 0:
                    return float(min(jarak))
            except Exception:
                continue
        return np.nan

    tqdm.pandas()
    gdf_titik['Jarak_ke_JalanUtama'] = gdf_titik['geometry'].progress_apply(
        lambda p: jarak_ke_jalan(G, p, jalan_utama_nodes, cutoff_levels)
    )
    gdf_titik['Jarak_ke_JalanSekunder'] = gdf_titik['geometry'].progress_apply(
        lambda p: jarak_ke_jalan(G, p, jalan_sekunder_nodes, cutoff_levels)
    )

    center = [gdf_titik[col_lat].mean(), gdf_titik[col_lon].mean()]
    m = folium.Map(location=center, zoom_start=12, tiles='CartoDB positron')

    # Layer jalan utama
    utama_edges = edges[edges['kategori']=='utama']
    if not utama_edges.empty:
        folium.GeoJson(
            utama_edges.to_crs(epsg=4326),
            name="Jalan Utama",
            style_function=lambda feat: {'color': 'red', 'weight': 2.2, 'opacity': 0.85}
        ).add_to(m)

    # Layer jalan sekunder
    sekunder_edges = edges[edges['kategori']=='sekunder']
    if not sekunder_edges.empty:
        folium.GeoJson(
            sekunder_edges.to_crs(epsg=4326),
            name="Jalan Sekunder",
            style_function=lambda feat: {'color': 'orange', 'weight': 1.6, 'opacity': 0.7}
        ).add_to(m)

    # Layer jalan lain
    others = edges[~edges['kategori'].isin(['utama','sekunder'])]
    if not others.empty:
        folium.GeoJson(
            others.to_crs(epsg=4326),
            name="Jalan Lainnya",
            style_function=lambda feat: {'color': 'gray', 'weight': 0.8, 'opacity': 0.4}
        ).add_to(m)

    for _, row in gdf_titik.iterrows():
        lat_v = row[col_lat]
        lon_v = row[col_lon]
        jarak_utama = row['Jarak_ke_JalanUtama']
        jarak_sek = row['Jarak_ke_JalanSekunder']
        popup_html = (
            f"<b>Koordinat:</b> ({lat_v:.6f}, {lon_v:.6f})<br>"
            f"<b>Jarak ke Jalan Utama:</b> {jarak_utama:.2f} m<br>"
            f"<b>Jarak ke Jalan Sekunder:</b> {jarak_sek:.2f} m"
        )
        folium.CircleMarker(
            location=[lat_v, lon_v],
            radius=5,
            color='blue',
            fill=True,
            fill_color='blue',
            fill_opacity=0.9,
            popup=folium.Popup(popup_html, max_width=320)
        ).add_to(m)

    folium.LayerControl().add_to(m)
    return m, gdf_titik.drop(columns='geometry'), df_detect

# ============================================================
#  Landuse per titik dan visualisasi
# ============================================================

def buat_df_titik_dari_summary_fix(summary_koordinat_v5_7, df_original):
    valid_cols = summary_koordinat_v5_7[summary_koordinat_v5_7['Status'] != 'Bukan Koordinat']['Kolom'].tolist()
    if len(valid_cols) < 2:
        print("Tidak cukup kolom koordinat valid")
        return None
    lat_col, lon_col = valid_cols[0], valid_cols[1]
    if df_original[lat_col].mean() > 0:
        lat_col, lon_col = lon_col, lat_col
    df_titik = df_original[[lat_col, lon_col]].rename(
        columns={lat_col:"LATITUDE", lon_col:"LONGITUDE"}
    ).copy()
    return df_titik

def ambil_landuse_per_titik_fix(df_titik):
    df_titik = df_titik.dropna(subset=["LATITUDE", "LONGITUDE"]).copy()
    df_titik["Landuse_OSM"] = np.nan
    gdf_titik = gpd.GeoDataFrame(
        df_titik,
        geometry=gpd.points_from_xy(df_titik["LONGITUDE"], df_titik["LATITUDE"]),
        crs="EPSG:4326"
    )
    gdf_titik = gdf_titik.dropna(subset=["geometry"])
    bounds = gdf_titik.total_bounds
    if np.isnan(bounds).any():
        return df_titik, None
    tags = {"landuse": True}
    try:
        landuse_gdf = ox.features_from_bbox(bounds, tags)
    except Exception:
        return df_titik, None
    if landuse_gdf.empty:
        return df_titik, None
    landuse_gdf = landuse_gdf[~landuse_gdf.geometry.isna()].copy()
    landuse_gdf = landuse_gdf[landuse_gdf.is_valid].copy()
    landuse_gdf["geometry"] = landuse_gdf["geometry"].apply(lambda g: g if g.geom_type=="Polygon" else g.convex_hull)
    landuse_gdf = landuse_gdf.set_crs(epsg=4326, allow_override=True)

    landuse_gdf_m = landuse_gdf.to_crs(epsg=3857)
    gdf_titik_m = gdf_titik.to_crs(epsg=3857).reset_index()
    for idx, row in tqdm(gdf_titik_m.iterrows(), total=len(gdf_titik_m)):
        point = row.geometry
        subset = landuse_gdf_m[landuse_gdf_m.geometry.contains(point)]
        if subset.empty:
            distances = landuse_gdf_m.geometry.distance(point)
            min_idx = distances.idxmin()
            df_titik.at[row["index"], "Landuse_OSM"] = landuse_gdf_m.at[min_idx, "landuse"]
        else:
            df_titik.at[row["index"], "Landuse_OSM"] = subset.iloc[0]["landuse"]
    return df_titik, landuse_gdf

def plot_landuse_titik_dan_polygon_enhanced(df_titik, landuse_gdf, col_lat="LATITUDE", col_lon="LONGITUDE", col_landuse="Landuse_OSM"):
    center_lat = df_titik[col_lat].mean()
    center_lon = df_titik[col_lon].mean()
    m = folium.Map(location=[center_lat, center_lon], zoom_start=13)

    landuse_unique = pd.concat([
        df_titik[col_landuse].dropna(),
        landuse_gdf["landuse"].dropna() if landuse_gdf is not None else pd.Series(dtype=str)
    ]).unique()
    cmap = colors.ListedColormap(cm.get_cmap("tab20").colors[:len(landuse_unique)])
    color_map = {lu: colors.rgb2hex(cmap(i)[:3]) for i, lu in enumerate(landuse_unique)}

    if landuse_gdf is not None and not landuse_gdf.empty:
        folium.GeoJson(
            landuse_gdf,
            style_function=lambda feature: {
                "fillColor": color_map.get(feature["properties"]["landuse"], "#808080"),
                "color": "black",
                "weight": 1,
                "fillOpacity": 0.4,
            },
            tooltip=folium.GeoJsonTooltip(fields=["landuse"], aliases=["Landuse:"])
        ).add_to(m)

    marker_cluster = MarkerCluster().add_to(m)
    for _, row in df_titik.iterrows():
        lu = row[col_landuse]
        if pd.isna(lu):
            color = "#808080"
            popup_text = "Landuse: Tidak ada data"
        else:
            color = color_map.get(lu, "#808080")
            popup_text = f"Landuse: {lu}"
        folium.CircleMarker(
            location=[row[col_lat], row[col_lon]],
            radius=5,
            color=color,
            fill=True,
            fill_opacity=0.7,
            popup=popup_text
        ).add_to(marker_cluster)

    return m